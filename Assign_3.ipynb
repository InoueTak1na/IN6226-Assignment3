{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a638717a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (5.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at d:\\anaconda\\lib\\site-packages\\huggingface_hub-0.19.4-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a245c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import json\n",
    "import os\n",
    "import zlib\n",
    "import re\n",
    "import tracemalloc\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d03919",
   "metadata": {},
   "source": [
    "# inverted  index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4607c460",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def create_inverted_index(file_path):\n",
    "    inverted_index = {}\n",
    "    \n",
    "    with open (input_file, 'r', encoding='latin-1') as file:\n",
    "        current_term = None\n",
    "        current_docs = []\n",
    "        \n",
    "        for line in file:\n",
    "            term, doc_id = line.strip().split()\n",
    "            \n",
    "            if term != current_term:\n",
    "                if current_term is not None:\n",
    "                    inverted_index[current_term] = current_docs\n",
    "                current_term = term\n",
    "                current_docs = [doc_id]\n",
    "            else:\n",
    "                current_docs.append(doc_id)\n",
    "        \n",
    "        # Adding the last term-doc pair\n",
    "        if current_term is not None:\n",
    "            inverted_index[current_term] = current_docs\n",
    "    \n",
    "    return inverted_index    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8485b6",
   "metadata": {},
   "source": [
    "#  persist the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0caaab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inverted_index(inverted_index, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(inverted_index, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_inverted_index(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        inverted_index = json.load(file)\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "535ea3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "input_file = 'output/output.txt'  # Path to the input file\n",
    "output_file = 'inverted_index1.json'  # Output file path\n",
    "inverted_index = create_inverted_index(input_file)\n",
    "save_inverted_index(inverted_index, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f1171",
   "metadata": {},
   "source": [
    "# Boolean Search with AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb66e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_search_AND(query, inverted_index):\n",
    "\n",
    "    query_terms = query.split()\n",
    "    result = None\n",
    "    \n",
    "    # Ensure that all query terms exist in the inverted index\n",
    "    for term in query_terms:\n",
    "        if term not in inverted_index:\n",
    "            return []\n",
    "    # Initialize result with the documents containing the first term\n",
    "    result = set(inverted_index[query_terms[0]])\n",
    "    # Perform AND operation with other terms\n",
    "    for term in query_terms[1:]:\n",
    "        result = result.intersection(inverted_index[term])\n",
    "        \n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # 转换为MB \n",
    "   \n",
    "\n",
    "    return list(result),memory_usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d027b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def boolean_search_AND_encode1(encoded_dict, query):\n",
    "    # 检查查询词是否都在压缩字典中\n",
    "    query_terms = query.split()\n",
    "    for term in query_terms:\n",
    "        if term not in encoded_dict:\n",
    "            return \"Query term '{}' not found in dictionary\".format(term)\n",
    "    \n",
    "    \n",
    "    postings_lists = []\n",
    "     \n",
    "    for term in query_terms:\n",
    "        encoded_postings = encoded_dict[term]\n",
    "        compressed_postings = json.loads(zlib.decompress(encoded_postings).decode())\n",
    "        \n",
    "        postings = []\n",
    "        prev_doc_id = 0\n",
    "        for gap in compressed_postings:\n",
    "            doc_id = prev_doc_id + gap\n",
    "            postings.append(doc_id)\n",
    "            prev_doc_id = doc_id\n",
    "        \n",
    "      \n",
    "        postings_lists.append(set(postings))\n",
    "    \n",
    "    result = set.intersection(*postings_lists)\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # 转换为MB         \n",
    "    return list(result), memory_usage\n",
    "  \n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83d990",
   "metadata": {},
   "source": [
    "# Boolean Search with ORandNOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ef60fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_search_ORandNOT(query, inverted_index):\n",
    "    query_terms = query.split()\n",
    "    result = set()\n",
    "    # Ensure that all query terms exist in the inverted index\n",
    "    for term in query_terms:\n",
    "        if term not in inverted_index:\n",
    "            return []\n",
    "    # Check for presence of NOT terms\n",
    "    not_terms = [term[1:] for term in query_terms if term.startswith('-')]\n",
    "    # Initialize result with the documents containing the first non-NOT term\n",
    "    for term in query_terms:\n",
    "        if not term.startswith('-'):\n",
    "            result.update(inverted_index[term])\n",
    "    # Perform AND operation with other non-NOT terms\n",
    "    for term in query_terms:\n",
    "        if not term.startswith('-'):\n",
    "            result = result.intersection(inverted_index[term])\n",
    "    # Exclude documents containing the NOT terms\n",
    "    for term in not_terms:\n",
    "        if term in inverted_index:\n",
    "            result.difference_update(inverted_index[term])\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # 转换为MB         \n",
    "    return list(result), memory_usage\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e077fa2",
   "metadata": {},
   "source": [
    "# Index Compression/Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "737b25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_number_from_path(document_path):\n",
    "    # 使用正则表达式匹配文档路径中的第一个数字\n",
    "    match = re.search(r'\\d+', document_path)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compress_postings(postings):\n",
    "    compressed_postings = []\n",
    "    prev_doc_id = 0\n",
    "    for doc_id in postings:\n",
    "        doc_id_hash = extract_number_from_path(doc_id)\n",
    "        gap = doc_id_hash - prev_doc_id   \n",
    "        compressed_postings.append(gap)\n",
    "        prev_doc_id = doc_id_hash  \n",
    "    return compressed_postings\n",
    "\n",
    "def encode_dictionary(dictionary):\n",
    "    encoded_dict = {}\n",
    "    for term, postings in dictionary.items():\n",
    "        compressed_postings = compress_postings(postings)\n",
    "        encoded_postings = zlib.compress(json.dumps(compressed_postings).encode())\n",
    "        encoded_dict[term] = encoded_postings\n",
    "    return encoded_dict\n",
    "\n",
    "def decode_postings(encoded_postings):\n",
    "    compressed_postings = json.loads(zlib.decompress(encoded_postings).decode())\n",
    "    postings = []\n",
    "    prev_doc_id = 0\n",
    "    for gap in compressed_postings:\n",
    "        doc_id = prev_doc_id + gap\n",
    "        postings.append(doc_id)\n",
    "        prev_doc_id = doc_id\n",
    "    return postings\n",
    "\n",
    "def decode_dictionary(encoded_dict):\n",
    "    dictionary = {}\n",
    "    for term, encoded_postings in encoded_dict.items():\n",
    "        postings = decode_postings(encoded_postings)\n",
    "        dictionary[term] = postings\n",
    "    return dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "81224b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "import json\n",
    "\n",
    "def search(encoded_dict, query):\n",
    "    if query not in encoded_dict:\n",
    "        return \"Query term not found in dictionary\"\n",
    "    \n",
    "    encoded_postings = encoded_dict[query]\n",
    "    compressed_postings = json.loads(zlib.decompress(encoded_postings).decode())\n",
    "    \n",
    "    postings = []\n",
    "    prev_doc_id = 0\n",
    "    for gap in compressed_postings:\n",
    "        doc_id = prev_doc_id + gap\n",
    "        postings.append(doc_id)\n",
    "        prev_doc_id = doc_id\n",
    "    \n",
    "    return postings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3940bed",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "590afd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_simi_ranking(query, inverted_index, ranknum):\n",
    "    \n",
    "    #Calculate value of IDF\n",
    "    index_len = len(inverted_index)\n",
    "    idf = {}\n",
    "    for term, doc_ids in inverted_index.items():\n",
    "        df = len(doc_ids)\n",
    "        idf[term] = math.log(index_len / (df + 1))\n",
    "        \n",
    "    #Calculate vector of TF-IDF\n",
    "    tfidf = collections.defaultdict(float)\n",
    "    query_terms = query.split()\n",
    "    for term in query_terms:\n",
    "        if term in idf:\n",
    "            tfidf[term] += 1\n",
    "    for term in tfidf:\n",
    "        tfidf[term] *= idf[term]\n",
    "        \n",
    "    #Calculate cos similarity\n",
    "    cos_simi = {}\n",
    "    for term in query_terms:\n",
    "        if term in inverted_index:\n",
    "            for doc_id in inverted_index[term]:\n",
    "                if doc_id not in cos_simi:\n",
    "                    cos_simi[doc_id] = 0\n",
    "                cos_simi[doc_id] += tfidf[term]\n",
    "                \n",
    "    mag = math.sqrt(sum(val ** 2 for val in tfidf.values()))\n",
    "    for doc_id in cos_simi:\n",
    "        doc_mag = math.sqrt(sum(val ** 2 for val in tfidf.values()))\n",
    "        cos_simi[doc_id] /= mag * doc_mag\n",
    "        cos_simi[doc_id] = round(cos_simi[doc_id], 2)\n",
    "        \n",
    "    #Rank by cos similarity\n",
    "    ranking_result = sorted(cos_simi.items(), key = lambda x: x[1], reverse = True)[:ranknum]\n",
    "    return ranking_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115af45",
   "metadata": {},
   "source": [
    "# measure part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "901f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(query, inverted_index):\n",
    "     \n",
    "    start_time = time.time()\n",
    "    result = cos_simi_ranking(query, inverted_index, 20)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(execution_time)\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # translate to MegaByte\n",
    "\n",
    "    return result, execution_time, memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603a716",
   "metadata": {},
   "source": [
    "# EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "79436c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file_path = \"inverted_index1.json\"  # 替换为您的索引文件路径\n",
    "inverted_index = load_inverted_index(index_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "93ac141f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03231620788574219\n",
      "Search Results: [('./HillaryEmails\\\\1.txt', 0.22), ('./HillaryEmails\\\\1861.txt', 0.22), ('./HillaryEmails\\\\3086.txt', 0.22), ('./HillaryEmails\\\\3388.txt', 0.22), ('./HillaryEmails\\\\3606.txt', 0.22), ('./HillaryEmails\\\\4371.txt', 0.22), ('./HillaryEmails\\\\5236.txt', 0.22), ('./HillaryEmails\\\\5237.txt', 0.22), ('./HillaryEmails\\\\5264.txt', 0.22), ('./HillaryEmails\\\\769.txt', 0.22), ('./HillaryEmails\\\\1537.txt', 0.17), ('./HillaryEmails\\\\1640.txt', 0.17), ('./HillaryEmails\\\\1643.txt', 0.17), ('./HillaryEmails\\\\3423.txt', 0.17), ('./HillaryEmails\\\\4220.txt', 0.17), ('./HillaryEmails\\\\4221.txt', 0.17), ('./HillaryEmails\\\\4309.txt', 0.17), ('./HillaryEmails\\\\1565.txt', 0.16), ('./HillaryEmails\\\\1718.txt', 0.16), ('./HillaryEmails\\\\2459.txt', 0.16)]\n",
      "Search Time: 0.03231620788574219 seconds\n",
      "Memory Usage: 386.86328125 MB\n"
     ]
    }
   ],
   "source": [
    "query = \"statement by your boss\"\n",
    "re1,ex1,mb1 = measure_performance(query, inverted_index)\n",
    "print(\"Search Results:\", re1)\n",
    "print(\"Search Time:\", ex1, \"seconds\")\n",
    "print(\"Memory Usage:\", mb1, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0f9fb3c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results (Before Compression): ['./HillaryEmails\\\\5264.txt', './HillaryEmails\\\\3086.txt', './HillaryEmails\\\\5236.txt', './HillaryEmails\\\\3606.txt', './HillaryEmails\\\\1861.txt', './HillaryEmails\\\\3388.txt', './HillaryEmails\\\\769.txt', './HillaryEmails\\\\4371.txt', './HillaryEmails\\\\1.txt', './HillaryEmails\\\\5237.txt']\n",
      "Search Time (Before Compression): 0.0010006427764892578\n",
      "Memory Usage (Before Compression): 386.86328125 MB\n"
     ]
    }
   ],
   "source": [
    "query = \"statement by your boss\"\n",
    "start_time0 = time.time() \n",
    "result,memory_before= boolean_search_AND(query, inverted_index)\n",
    "end_time0 = time.time()\n",
    "execution_time0 = end_time0 - start_time0\n",
    "\n",
    "print(\"Search Results (Before Compression):\", result)\n",
    "print(\"Search Time (Before Compression):\", execution_time0)\n",
    "print(\"Memory Usage (Before Compression):\", memory_before, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a4d9856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results (After Compression): [43, 215]\n",
      "Search Time (After Compression): 0.0 seconds\n",
      "Memory Usage (After Compression): 406.86328125 MB\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query= \"sad longstand\"\n",
    "encoded_index = encode_dictionary(inverted_index)\n",
    "\n",
    "start_time7 = time.time()\n",
    "result1,memory_after = boolean_search_AND_encode1(encoded_index,query)\n",
    "end_time7 = time.time()\n",
    "execution_time7 = end_time7 - start_time7\n",
    "\n",
    "  \n",
    "print(\"Search Results (After Compression):\", result1)\n",
    "print(\"Search Time (After Compression):\", execution_time7,\"seconds\")\n",
    "print(\"Memory Usage (After Compression):\", memory_after, \"MB\") \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d381333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents satisfying the query: (['./HillaryEmails\\\\5264.txt', './HillaryEmails\\\\3086.txt', './HillaryEmails\\\\5236.txt', './HillaryEmails\\\\3606.txt', './HillaryEmails\\\\1861.txt', './HillaryEmails\\\\3388.txt', './HillaryEmails\\\\769.txt', './HillaryEmails\\\\4371.txt', './HillaryEmails\\\\1.txt', './HillaryEmails\\\\5237.txt'], 355.58984375)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"statement by your boss\"\n",
    "\n",
    "start_time = time.time()\n",
    "result = boolean_search_AND(query, inverted_index)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "# i = 0\n",
    "# for terms, doc_ids in inverted_index.items():\n",
    "#     if i > 20:\n",
    "#         break\n",
    "#     else:\n",
    "#         print(terms, \" \", len(doc_ids))\n",
    "#         i += 1\n",
    "print(\"Documents satisfying the query:\", result)\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28805de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
